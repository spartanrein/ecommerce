{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Amazon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_fashion = pd.read_csv('amazon_fashion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grey/Camo Stingray Escape Bodybuilding Weightlifting MMA &amp; Boxing Shoe</td>\n",
       "      <td>Otomix</td>\n",
       "      <td>133.00</td>\n",
       "      <td>athletic shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women's Hexaffect 5.0 MTM Running Shoe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.95</td>\n",
       "      <td>athletic shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women's Stan Smith Fashion Sneakers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.62</td>\n",
       "      <td>fashion sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Women's Summer Casual Sleeveless Long Sleeve Mini Plain Pleated Tank Vest Dresses T-Shirt Dress</td>\n",
       "      <td>VERABENDI</td>\n",
       "      <td>9.99</td>\n",
       "      <td>dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evie Nubuck Mule, 6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.99</td>\n",
       "      <td>mules and clogs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      product_name  \\\n",
       "0  Grey/Camo Stingray Escape Bodybuilding Weightlifting MMA & Boxing Shoe                            \n",
       "1  Women's Hexaffect 5.0 MTM Running Shoe                                                            \n",
       "2  Women's Stan Smith Fashion Sneakers                                                               \n",
       "3  Women's Summer Casual Sleeveless Long Sleeve Mini Plain Pleated Tank Vest Dresses T-Shirt Dress   \n",
       "4  Evie Nubuck Mule, 6.5                                                                             \n",
       "\n",
       "       brand   price          category  \n",
       "0  Otomix     133.00  athletic shoes    \n",
       "1  NaN        35.95   athletic shoes    \n",
       "2  NaN        38.62   fashion sneakers  \n",
       "3  VERABENDI  9.99    dresses           \n",
       "4  NaN        54.99   mules and clogs   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_fashion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281267, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_fashion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only interested on the 'product_name' and 'category' columns, so we can drop the other 2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_fashion.drop(['brand', 'price'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's check if the product_name column includes any nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name    29\n",
       "category        0 \n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_fashion.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_fashion.dropna(subset=['product_name'], how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name    0\n",
       "category        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_fashion.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we eliminated the unwanted columns and the rows with nan values, we can split the data into X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = amazon_fashion['product_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = amazon_fashion['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of the data into word vectors and embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to test 2 distinct approaches for the data. The first one using Bag of Words & TF-IDF, and the second one using Embeddings from fastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words & TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before turning the product names into a bag of words, let's do some pre-processing first, which includes: apply lower case, remove numbers and special characters, remove most frequent words that won't help the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_amazon_fashion = X.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    grey/camo stingray escape bodybuilding weightlifting mma & boxing shoe                         \n",
       "1    women's hexaffect 5.0 mtm running shoe                                                         \n",
       "2    women's stan smith fashion sneakers                                                            \n",
       "3    women's summer casual sleeveless long sleeve mini plain pleated tank vest dresses t-shirt dress\n",
       "4    evie nubuck mule, 6.5                                                                          \n",
       "Name: product_name, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_amazon_fashion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_amazon_fashion = bow_amazon_fashion.map(lambda x: re.sub(r'[^a-zA-Z ]', '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_amazon_fashion = bow_amazon_fashion.map(lambda x: re.sub(r'^[\\d]*', '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "bow_amazon_fashion = bow_amazon_fashion.apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "womens    205123\n",
       "women     35759 \n",
       "shoes     27282 \n",
       "sleeve    23510 \n",
       "long      22917 \n",
       "casual    22593 \n",
       "dress     21995 \n",
       "high      19843 \n",
       "pants     17193 \n",
       "size      16100 \n",
       "flat      15786 \n",
       "toe       14216 \n",
       "short     14082 \n",
       "top       13305 \n",
       "skirt     13118 \n",
       "waist     12951 \n",
       "plus      12179 \n",
       "lace      12030 \n",
       "socks     11311 \n",
       "jacket    11265 \n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq = pd.Series(' '.join(bow_amazon_fashion).split()).value_counts()[:20]\n",
    "most_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that some words are reflective to the actual category the item belongs to, while others won't help the classification process. Words such as 'womens' and 'women' will hence be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq = list(['womens', 'women', 'size'])\n",
    "\n",
    "bow_amazon_fashion = bow_amazon_fashion.apply(lambda x: \" \".join(x for x in x.split() if x not in most_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split the data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_train_data, bow_test_data, bow_train_labels, bow_test_labels = train_test_split(\n",
    "    bow_amazon_fashion, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188429,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92809,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, create the TF_IDF vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=29765)\n",
    "tfidf_vect.fit(bow_train_data)\n",
    "\n",
    "bow_train_data =  tfidf_vect.transform(bow_train_data)\n",
    "bow_test_data =  tfidf_vect.transform(bow_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Embeddings from fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and Training the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(ml_model, train_data, train_labels, test_data, test_labels):\n",
    "    \n",
    "    # Training\n",
    "    model = ml_model\n",
    "    model.fit(train_data, train_labels)\n",
    "    y_pred = model.predict(test_data)\n",
    "\n",
    "    # Evaluation\n",
    "    acc = accuracy_score(test_labels, y_pred)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the models with the bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_acc = modeling(LinearSVC(), bow_train_data, bow_train_labels, bow_test_data, bow_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the dataset using the SVC Classifier: 81.86\n"
     ]
    }
   ],
   "source": [
    "linear_svc_acc = '%.2f'%(linear_svc_acc * 100)\n",
    "print(\"Accuracy on the dataset using the SVC Classifier: {}\".format(linear_svc_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_acc = modeling(LogisticRegression(), bow_train_data, bow_train_labels, bow_test_data, bow_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the dataset using the Logistic Regression Classifier: 81.78\n"
     ]
    }
   ],
   "source": [
    "log_reg_acc = '%.2f'%(log_reg_acc * 100)\n",
    "print(\"Accuracy on the dataset using the Logistic Regression Classifier: {}\".format(log_reg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_acc = modeling(RandomForestClassifier(), bow_train_data, bow_train_labels, bow_test_data, bow_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the dataset using the Random Forest Classifier: 78.96\n"
     ]
    }
   ],
   "source": [
    "random_forest_acc = '%.2f'%(random_forest_acc * 100)\n",
    "print(\"Accuracy on the dataset using the Random Forest Classifier: {}\".format(random_forest_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_acc = modeling(GaussianNB(), bow_train_data.toarray(), bow_train_labels, bow_test_data.toarray(), bow_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the dataset using the Naive Bayes Classifier: 33.80\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_acc = '%.2f'%(naive_bayes_acc * 100)\n",
    "print(\"Accuracy on the dataset using the Naive Bayes Classifier: {}\".format(naive_bayes_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgboost_acc = modeling(XGBClassifier(), bow_train_data, bow_train_labels, bow_test_data, bow_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the dataset using the XGBoost Classifier: 77.77\n"
     ]
    }
   ],
   "source": [
    "xgboost_acc = '%.2f'%(xgboost_acc * 100)\n",
    "print(\"Accuracy on the dataset using the XGBoost Classifier: {}\".format(xgboost_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [svc_acc, log_reg_acc, random_forest_acc, naive_bayes_acc, xgboost_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LogisticRegression()\n",
    "final_model.fit(bow_train_data, bow_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_proba(product_name):\n",
    "    \n",
    "    name = pd.Series([product_name])\n",
    "    \n",
    "    name =  tfidf_vect.transform(name)\n",
    "    \n",
    "    cat = final_model.predict(name)\n",
    "    prob = final_model.predict_proba(name)\n",
    "    prob = \"{:.2f}\".format(np.amax(prob)*100)\n",
    "    \n",
    "    result = \"The item named {} was fitted under the {} category, with a probability of {}%\".format(\n",
    "        product_name, cat, prob)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The item named Levis High Rise Skinny Jeans was fitted under the ['jeans'] category, with a probability of 94.37%\n"
     ]
    }
   ],
   "source": [
    "result = get_category_proba('Levis High Rise Skinny Jeans')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The item named Long Sleeve Knit Cardigan was fitted under the ['sweaters'] category, with a probability of 93.76%\n"
     ]
    }
   ],
   "source": [
    "result = get_category_proba('Long Sleeve Knit Cardigan')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
